{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "SEED = 42\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data's first two rows are headers.\n",
    "The first row contains the configuration numbers, but spaced one apart.\n",
    "The second row contains the completion time and mistakes under each configuration number column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df. We can make each row contain the config num, completion time, and mistakes.\n",
    "# Therefore, the data will contain 3 columns: config_num, completion_time, mistakes\n",
    "# and the data will multiply the number of rows by the 7 (because there are 7 configs)\n",
    "\n",
    "converted_df:pd.DataFrame = pd.DataFrame(columns=['nick', 'config_num', 'completion_time', 'mistakes'])\n",
    "\n",
    "# For each participant\n",
    "num_participants = df.shape[0] - 1 # -1 because the first two rows are headers\n",
    "\n",
    "for i in range(num_participants):\n",
    "    # For each config\n",
    "    for j in range(1, 8):\n",
    "        config_num = j-1\n",
    "        \n",
    "        # Mistakes and completion time are in the same row\n",
    "        # But they are in different columns. Each config has 2 columns for mistakes and completion time\n",
    "        mistakes_col = j * 2\n",
    "        completion_time_col = j * 2 - 1\n",
    "\n",
    "        mistakes = df.iloc[i+1, mistakes_col]\n",
    "        completion_time = df.iloc[i+1, completion_time_col]\n",
    "\n",
    "        # Add row to converted_df\n",
    "        converted_df = pd.concat([converted_df, pd.DataFrame([[df.iloc[i+1, 0], config_num, completion_time, mistakes]], columns=['nick', 'config_num', 'completion_time', 'mistakes'])])\n",
    "\n",
    "        # Remove index\n",
    "        converted_df = converted_df.reset_index(drop=True)\n",
    "\n",
    "converted_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Previous shape: \", df.shape)\n",
    "print(\"New shape: \", converted_df.shape)\n",
    "\n",
    "df = converted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our current data, the data uses configurations. However, that does not tell us enough. We can add three new variables (`size`, `color`,  and `position`) to give us more insights about our data.\n",
    "- The baseline by default has `size: regular`, `color: yellow`, and `position: top`.\n",
    "- Config 1 and 2 changes the size into `small` and `large`\n",
    "- Config 3 and 4 changes the color into `blue` and `black`\n",
    "- Config 5 and 6 changes the position into `sticky` and `bottom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column for size, color, and position. Filled based on config_num\n",
    "\n",
    "df['size'] = df['config_num'].apply(lambda x: 'regular' if x == 0 or x == 3 or x == 4 else 'small' if x == 1 else 'large')\n",
    "df['color'] = df['config_num'].apply(lambda x: 'yellow' if x == 0 or x == 1 or x == 2 or x == 5 else 'blue' if x == 3 else 'black' if x == 4 else 'yellow')\n",
    "df['position'] = df['config_num'].apply(lambda x: 'top' if x == 0 or x == 1 or x == 2 or x == 3 or x == 4 else 'sticky' if x == 5 else 'bottom')\n",
    "\n",
    "df.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data currently has outliers so we have to remove them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "\n",
    "# Convert size, color, and position to numerical values (0, 1, 2)\n",
    "# df_cleaned['size'] = df_cleaned['size'].apply(lambda x: 1 if x == 'small' else 0 if x == 'regular' else 2)\n",
    "# df_cleaned['color'] = df_cleaned['color'].apply(lambda x: 1 if x == 'blue' else 2 if x == 'black' else 0)\n",
    "# df_cleaned['position'] = df_cleaned['position'].apply(lambda x: 1 if x == 'sticky' else 2 if x == 'top' else 0)\n",
    "\n",
    "# Remove outliers based on completion time (and possibly other features, just edit the features_of_interest)\n",
    "features_of_interest = ['completion_time']\n",
    "clf = IsolationForest(max_samples=100, random_state=SEED)\n",
    "clf.fit(df_cleaned[features_of_interest])\n",
    "df_cleaned['anomaly'] = clf.predict(df_cleaned[features_of_interest])\n",
    "\n",
    "# Plot the data to reveal outliers in completion time using histograms\n",
    "# Make anomalies red x's and normal data blue dots\n",
    "completion_times = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "# Create a histogram with adjusted x-axis labels and outliers in red\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram for normal data in blue\n",
    "plt.hist(completion_times, bins=20, alpha=0.5, color='blue', edgecolor='black', label='Normal')\n",
    "\n",
    "# Detect outliers using IQR or other methods (replace this with your outlier detection code)\n",
    "Q1 = np.percentile(completion_times, 25)\n",
    "Q3 = np.percentile(completion_times, 75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_threshold = 1.5 * IQR\n",
    "outliers = completion_times[(completion_times < Q1 - outlier_threshold) | (completion_times > Q3 + outlier_threshold)]\n",
    "\n",
    "# Plot histogram bars for outliers in red\n",
    "plt.hist(outliers, bins=20, alpha=0.5, color='red', edgecolor='black', label='Outliers')\n",
    "\n",
    "plt.xlabel('Completion Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Completion Time')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.legend()\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()\n",
    "\n",
    "# Filter out outliers based on completion time\n",
    "df_cleaned = df_cleaned[df_cleaned['anomaly'] == 1]\n",
    "\n",
    "# Drop the 'anomaly' column\n",
    "df_cleaned = df_cleaned.drop('anomaly', axis=1)\n",
    "\n",
    "print(\"Previous shape:\", df.shape)\n",
    "print(\"New shape after removing outliers based on completion time:\", df_cleaned.shape)\n",
    "\n",
    "df_cleaned.head(14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert our initial categorical features into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert size, color, and position to numerical values (0, 1, 2)\n",
    "df_cleaned['size'] = df_cleaned['size'].apply(lambda x: 1 if x == 'small' else 0 if x == 'regular' else 2)\n",
    "df_cleaned['color'] = df_cleaned['color'].apply(lambda x: 1 if x == 'blue' else 2 if x == 'black' else 0)\n",
    "df_cleaned['position'] = df_cleaned['position'].apply(lambda x: 1 if x == 'sticky' else 2 if x == 'top' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin splitting the data for our models to use. We conduct an 80-20 train-test split. Validation split is no longer needed because it's done by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, and test sets. Goal is completion time\n",
    "X = df_cleaned[['size', 'color', 'position', 'config_num']]\n",
    "y = df_cleaned['completion_time']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Count number of samples per split\n",
    "print(\"Total number of samples:\", len(X))\n",
    "print(\"Number of samples in training set:\", len(X_train))\n",
    "print(\"Number of samples in test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Searching (GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
